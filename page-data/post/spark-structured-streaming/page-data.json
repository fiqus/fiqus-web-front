{
    "componentChunkName": "component---src-blog-templates-blog-post-js",
    "path": "/post/spark-structured-streaming",
    "result": {"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"a5b3f836-e74b-509d-9a8b-401dd8c4b46b","html":"<h1>Creating an application with Spark Structured Streaming</h1>\n<h3>Code, configurations and considerations</h3>\n<p><a href=\"https://spark.apache.org/\">Apache Spark</a> is an open-source, distributed processing system used for big data workloads. designed to be fast and resilient.\nIt utilizes in-memory caching and optimized query execution for fast queries against data of any size.\nWith APIs for <code>Java</code>, <code>Scala</code>, <code>Python</code> and <code>R</code>.\nIt has <em>Lazy</em> evaluation, which means any transformation made on the RDDs or Dataframes  creates a logical flow of operations known as <em>Directed Acyclic Graph (DAG)</em> which groups operations to improve efficiency and only will execute the operations when the output is needed.</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 684px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/544f7/apache-spark-circulo.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAAsTAAALEwEAmpwYAAABmUlEQVQoz41SXWvbMBTtL+/b3vcvSvfQp21txqAdhbSlW4MZlJJQiB3ipLFsSZZlfd6rYSv98Eg/zoM4SDq6516dvbALiC94eBV7OzUYgoFHivpD4ggDON88iOIeQ1DO/86uprNpnuf96x12iD1gq21HMFSNqIsFAnrEjBTWGkB8ozKuNuXZ5M55AAAMoSBV04OWZax2MR4nSZKm6f9iABCcMV4rB7Tq4L2PR85Zyli3RSnntZRyIEb0HgRgiN6stUKIENA4b9hGTb7VZG2d344UEQCexd4V4+vPBz+/nyazFakYraSUo5PRyejH0ZfD2/Nj2zDCa75Ip5/209lsvljERra2tdHScNz6dIyx5XJJK0rKShlT17VzrnPYyjjzYc/GWFKKh3WWZayHdS5+jGpbzjml1FqrjFFKvRD3zDBKk0l+8+fq8tL3LZVlKaXU2hBCurIhNE3DGOOcD3oehKxfhTJZvu79odJtFL+VMARAgPhDF3/vvv4ahxA2Yjlf3ZOiigVfTdggoVpp1cZ7AOCce7L6TrY/jn/famVIErhXjAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/e922d/apache-spark-circulo.webp 375w,\n/static/4e23ec14fd006dc3f61b43fa874ea9f0/ffa34/apache-spark-circulo.webp 684w\"\n              sizes=\"(max-width: 684px) 100vw, 684px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/ae393/apache-spark-circulo.png 375w,\n/static/4e23ec14fd006dc3f61b43fa874ea9f0/544f7/apache-spark-circulo.png 684w\"\n            sizes=\"(max-width: 684px) 100vw, 684px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/544f7/apache-spark-circulo.png\"\n            alt=\"Spark ecosystem\"\n            title=\"Spark ecosystem\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Spark ecosystem</figcaption>\n  </figure></p>\n<p>One of the newest features of Spark is the <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\">Structured Streaming</a> that provides fast, scalable, fault-tolerant, end-to-end exactly-once stream processing without the user having to reason about streaming.</p>\n<p>You can express your streaming computation the same way you would express a batch computation on static data. The <strong>Spark SQL</strong> engine will take care of running it incrementally, continuously and updating the final result as streaming data continues to arrive. You can use the <a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html\">Dataset/DataFrame</a> API to express streaming aggregations, event-time windows, stream-to-batch joins.</p>\n<p>For a project we had to make metrics over the last 24 hours period reading incoming log lines, sum the new ones and discarding the old ones and outputting the metrics every ~5 minutes.\nFor solving this problem we used <strong>Structured Streaming</strong> running on an AWS EMR Cluster.</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 320px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/8980b/so-apache-spark-in-theory-enough-show-me-the-code.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 96.875%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAH/xAAXAQADAQAAAAAAAAAAAAAAAAABAwQC/9oADAMBAAIQAxAAAAGvuaxVM0QZokbjqAP/xAAYEAEBAQEBAAAAAAAAAAAAAAABAgAxEP/aAAgBAQABBQLNePIlZwGe0C//xAAaEQABBQEAAAAAAAAAAAAAAAACAAEQERIx/9oACAEDAQE/AXMb4tjP/8QAFhEBAQEAAAAAAAAAAAAAAAAAEQAQ/9oACAECAQE/ASN//8QAGRAAAwADAAAAAAAAAAAAAAAAARAhACIx/9oACAEBAAY/AnDc2C4H/8QAGxAAAwADAQEAAAAAAAAAAAAAAAERITGBUWH/2gAIAQEAAT8hTa0N9hbkdtuAg+DRZVdYI08y+GguGsw//9oADAMBAAIAAwAAABC4B3//xAAZEQADAAMAAAAAAAAAAAAAAAAAAREhMVH/2gAIAQMBAT8Qc6CltCeCH//EABgRAQADAQAAAAAAAAAAAAAAAAEAEBEx/9oACAECAQE/EBB2brZ//8QAHBABAQEBAAMBAQAAAAAAAAAAAREAITFhkUFx/9oACAEBAAE/EJtIW/3EV5pHvn7m1NvbrsEdL2esBSteqp+OAoldZyIBGboah89Y6VQr4u//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/5530d/so-apache-spark-in-theory-enough-show-me-the-code.webp 320w\"\n              sizes=\"(max-width: 320px) 100vw, 320px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/8980b/so-apache-spark-in-theory-enough-show-me-the-code.jpg 320w\"\n            sizes=\"(max-width: 320px) 100vw, 320px\"\n            type=\"image/jpeg\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/8980b/so-apache-spark-in-theory-enough-show-me-the-code.jpg\"\n            alt=\"image\"\n            title=\"image\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">image</figcaption>\n  </figure></p>\n<p>Some simple examples can be found in the <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\">Spark documentation</a>\nBut in real life, solutions will be more complex than that, so here we share a simplified solution of what we have done:</p>\n<deckgo-highlight-code language=\"python\" terminal=\"ubuntu\"  >\n          <code slot=\"code\"># imports\nfrom datetime import datetime\nfrom pyspark.sql.types import StructType, StringType, StructField, \\\n   DoubleType, BooleanType, IntegerType\nfrom pyspark.sql import functions as F\n\n# var definition\nhours_window = 24\nsliding_window = 5\ncheckpoint_dir = &#39;hdfs:///checkpoint_folder/&#39;\n\n# helper to create types\ndef _get_types(types_dict):\n   return StructType([(StructField(f_name, f_type, True)) for f_name, f_type in types_dict.items()])\n\n# structure types for the data streaming\nLOGLINE_SCHEMA = _get_types({\n   &#39;timestamp&#39;: StringType(),\n   &#39;cost&#39;: DoubleType(),\n   &#39;clicks&#39;: DoubleType(),\n})\n\n# read stream definition\nlogline_df = self.spark \\\n   .readStream \\\n   .schema(LOGLINE_SCHEMA) \\\n   .parquet(&#39;hdfs:///mydata/*&#39;)\n\n# convert timestamp field for window operation\nlogline_df = logline_df.withColumn(&#39;timestamp&#39;, F.to_timestamp(&#39;timestamp&#39;))\n\n\n# add watermark definition\nlogline_df = logline_df.withWatermark(&#39;timestamp&#39;, &#39;1 minute&#39;)\n\n\n# compute the metrics\nmetrics_df = logline_df.groupBy(\n   F.window(\n      logline_df.timestamp, f&#39;{hours_window} hours&#39;, \n      f&#39;{sliding_window} minutes&#39;\n   ),\n   logline_df.campaign_eid\n) \\\n.agg(\n   F.sum(&#39;cost&#39;).alias(&#39;cost&#39;),\n   F.sum(&#39;clicks&#39;).alias(&#39;clicks&#39;)\n)\n\n# start streaming\nquery = metrics_df.writeStream \\\n   .option(&quot;checkpointLocation&quot;, checkpoint_dir) \\\n   .foreachBatch(collect_metrics_fn) \\\n   .outputMode(&#39;append&#39;) \\\n   .trigger(processingTime=f&#39;{sliding_window} minutes&#39;) \\\n   .start()\n\n# function called for each batch\ndef collect_metrics_fn(df, epoch_id):\n   # do any operations needed in the dataframe\n   df = df.withColumn(&#39;timestamp&#39;, F.lit(datetime.now()))\n   # output dataframe\n   df.write.mode(&#39;overwrite&#39;).parquet(&#39;hdfs:///output&#39;)</code>\n        </deckgo-highlight-code>\n<p>In the code we can see that we have called <code>.readStream</code>\nto define the source where we are going to read our <a href=\"https://databricks.com/glossary/what-is-parquet\">parquet</a> files, in this case  our path is <code>hdfs:///mydata/</code>.\nIn this example we are using the <em>Hadoop Distributed File System.</em></p>\n<p>More information about HDFS:\n<a href=\"https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html\">https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html</a></p>\n<p>And in this section</p>\n<deckgo-highlight-code language=\"python\" terminal=\"ubuntu\"  >\n          <code slot=\"code\">   F.window(\n      logline_df.timestamp, f&#39;{hours_window} hours&#39;, \n      f&#39;{sliding_window} minutes&#39;\n   )</code>\n        </deckgo-highlight-code>\n<p>We define a window period of 24 hours using the <em>timestamp</em> field, and sliding every 5 minutes.</p>\n<p>To start the streaming we need to call the <code>writeStream</code> function.</p>\n<p>The <code>checkpoint</code> folder definition is very important, because if our job fails or gets restarted will try first to recover from the checkpointed data without having to process all the data from scratch again.</p>\n<p>This will not be possible only if the structure of input data or the streaming queries have changed and breaks the compatibility with the checkpoint structure. If this happens the checkpoint folder needs to be removed <em>manually</em> before launching a new job.\nThe <code>outputMode</code> defines how we want the <code>window</code> to be processed: the <code>append</code> mode will output each window only once the period is considered finished (considering the window + the watermark field).\nOn the other hand, the <code>update</code> mode outputs every window each time it has new data that falls into that period.</p>\n<p>More details about <code>output modes</code> can be found <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-modes\">here</a></p>\n<p>And finally the <code>foreachBatch</code> option allows passing a function to be called on each batch. It is possible to do manipulations, like adding more fields and writing the output to a desired location.</p>\n<p>The parameter <code>epoch_id</code> it’s an unique identifier to ensure a only-once guarantee at the moment of writing or processing the data frame.</p>\n<h3>Some useful configurations for long running jobs</h3>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1100px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b9b0687874e23c0e576a988d6dda404a/28a3f/spark-defaults.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADKklEQVQozwXBWUybBQDA8Y+jrBz9SgujwIBBoVBbKqOsHKXS0FIoIA7G4SwKYjlKAA/CwE03jgTWadgYRQEBG6RAGGMhmct0kTnNEvXBPeiUZIlOiCZmyoPZXnzx7+8nnLMf5kJVApM18UzVp+JrK8TXnM10q5ErrmO8XabG+4KW0+V63ipN50d/C3/deA1/xzECPUU8vd3C4806bng0fDtsQhiriGOiSsWIQ4m3IZON5Y/YWJ5naXKU9aUFrs7PsDzez87NbS4On+Oyd4JPrwXYWl3k5tVP+OerXtjtYX+lmjsDBoTW4yJNOXJOZou8mBNNS34iroKjuHNU7Jwu4fGtPnbHrHz/ei7tuXHkxYjcGrSxHzjFVm8eT+644X4Hu1Nm1trUCE6tSFl6FM4sGc/r5FRrZdjSIpgoioG1Gtjt42DRyb3GRDbqkrDLQwi0GXl6vY5tdxr/fu7i0QclPHi/hEf+agSrOhKHJooanZyXjEpceUrqDQoGjUq+8+j5c9LK7yP57F2w8XDISGuqlPPlav5YrGKrI4sfvIXcfkPLwbVa/rvbgmBLl1GZJeLQyHguNYJclQS7OoJOrZyvOw2wdZK/3zPzZM7Or0PPMp6v4Kw5kZ/HLWx3ZbDmVvPNaBH7c3buj5kQilLCSRFDkUmCORIVxkyHmZ0BM4tVybxTGMdP/QY2alP5rFHDg24t7x6PplMfS322iq7iBAKvanh4ycbenJ0vBvQIUaHBxEpDUYUJvFmSzC/nzcw6klg/kcaQSUW3Ts7egBG8FtZPHMGpkmIQDyERghDDw2kuSKCrUEGvRcm9ETNCtCQYvSKMZGkQq24TXzalcsYgY7P5GRbK40kSBDzZEfQaDuGMEWhPj8QcH0G0NAiHTqShIAGLNg5ThoLK3FiEtMgQMuWhpEiD2Owr5mC4gN9mXmH/Yw8vm3WUWoqpKTFSY7fSVWFltKmc/lMVeOpLGe1poLXSSHWOijJDPFZ9HEKGXEKGGEKmGMIZh5q77kwWBju5PD1Lu9uNzzeN78olVuanuO7zsvLhNMsLM6z6Z/EvLXK220Wj6TANhUepNSbyP5o+yRGWAWZAAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/b9b0687874e23c0e576a988d6dda404a/e922d/spark-defaults.webp 375w,\n/static/b9b0687874e23c0e576a988d6dda404a/3ea8a/spark-defaults.webp 750w,\n/static/b9b0687874e23c0e576a988d6dda404a/cb2d6/spark-defaults.webp 1100w\"\n              sizes=\"(max-width: 1100px) 100vw, 1100px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/b9b0687874e23c0e576a988d6dda404a/ae393/spark-defaults.png 375w,\n/static/b9b0687874e23c0e576a988d6dda404a/e9985/spark-defaults.png 750w,\n/static/b9b0687874e23c0e576a988d6dda404a/28a3f/spark-defaults.png 1100w\"\n            sizes=\"(max-width: 1100px) 100vw, 1100px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/b9b0687874e23c0e576a988d6dda404a/28a3f/spark-defaults.png\"\n            alt=\"image\"\n            title=\"image\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">image</figcaption>\n  </figure></p>\n<p><code>spark.sql.streaming.minBatchesToRetain</code></p>\n<p>This setting indicates the minimum number of checkpoints to be saved for recovery in case of an error.\nThe default it’s <strong>100</strong>, which can make the size of the folder too big. In the case of processing big amounts of data and running for a long period of time, we’ve seen better performance using smaller values, so we had good results with 5.</p>\n<p><code>spark.cleaner.referenceTracking.cleanCheckpoints</code></p>\n<p>This is another important configuration, which by default it’s in false. In true, it will remove the checkpoints that have lost any references.</p>\n<p><code>spark.default.parallelism</code></p>\n<p>Tuning this configuration it’s important, as it defines how much <em>parallelism</em> a job can have, but it depends on the resources available. Too much parallelism will make the task too small and a lot of overhead, and too low parallelism will underutilize the executors.</p>\n<p>A simple math to set a starting value can be the following:\n<code>spark.default.parallelism = spark.executor.instances * spark.executors.cores * 2 (or 3)</code></p>\n<blockquote>\n<p><em>More useful configurations for Structured Streming jobs can be found here:</em></p>\n</blockquote>\n<p><a href=\"https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-properties.html\">https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-properties.html</a></p>\n<h3>How to deploy a yarn application in EMR</h3>\n<p><code>aws emr add-steps --cluster-id ClusterID --steps Type=spark,Name=MyApp,Args=[--deploy-mode,cluster,--master,yarn,--conf,spark.yarn.submit.waitAppCompletion=False,--conf,spark.yarn.appMasterEnv.profile=$(profile),--py-files,s3://my-bucket/app-dependencies.zip,s3://my-bucket/my_app.py],ActionOnFailure=CONTINUE</code></p>\n<p>With <code>aws emr add-steps</code> command we can add a step that will create an application, and setting <code>waitAppCompletion=False</code> the step will not wait the app to finish. Being a streaming job, ideally will not finish.</p>\n<p>And with this parameter:\n<code>spark.yarn.appMasterEnv.profile</code></p>\n<p>We can send environment variables to the application, like for example the profile (<em>staging / produccion</em>), here the example on how to get it in the code:</p>\n<p><code>PROFILE = os.getenv('profile', 'staging')</code></p>\n<p><strong>Spark Structured streaming</strong> is a great tool, but requires some effort and knowledge to get good results. We hope these insights will help you in this venture.</p>","frontmatter":{"lang":"en","type":"post","title":"Spark Structured Streaming","author":"Agustin Recouso","slug":"/spark-structured-streaming","date":"2022-01-24","tags":["python","spark","big-data"],"image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAIAAABSJhvpAAAACXBIWXMAAAsTAAALEwEAmpwYAAACe0lEQVQ4y5VT30/TUBjtH2diIo8YSiIPQmQQS3RB0ABLEPoATH4NHWNbqaLDkcgDEXBCRmFhhsGWjHUgI9nKWEkV19lu7ehc23sN6VzMshg5ubn57s05+b6bew4CbwgAANC16wUAciPRj9BmWRKNI4QQqcOpAYRA1yCEv35e7nXeOlt6VRb47MGWcslWxLqu/2HWbwshZNc9zOLUmXfmxPY0hN0uXqRqOxcK+VwuJ4qiLMv5vCgKQkEp8XTooKcx4xkvC1kIYfLNWC4arIwNACBJsru7m2VZmqYTiZNwOBwMBjmOo2OH++HI1bfM97ej2+7xXF4CmpqwDwhHBxUxRVEoim5sbLBsxufzzc05eJ5X1bLX+54kyWKxmEyff6a2n/U+cRDEqtsW72s6sVsqYkmSULTJ7/cvL38YGhqamprE8WGHY3ZiYhzH8ZHRkd7eHrfL2Xi30WQylRTliktfXV5ci1VV5TguFAo1NNxpb3+QyWQYhsGwh62t92VZZhimpeWexTKQTCabm5vMZvN5Om28tCLGMKytrdVmm0ZRtKPDZDY/Pj1NeDzvurowq3UMx4fn54loNGq1jlHUVn9/nyiKpVKpMrYgCCzLplLJwcFBnud3AgFqJ5BimHWfb+2TL0bHw5FIYHdXkiQIIc/zsiyDqkmMSlGUbPb6J/bDkVkn4SLIF5PTxOuFWafb7nQteBarzCqQqquqDtN1XdM0Y19ZXdv0U0fHXw9jdIyOf9kLxY+OJUk2mEiNN2s8s/JxzeNdemmfszwfnrE7HC6is+tRjI4bpkTqRqBaa5qmqioAQNM0457n+UJBqtP5H4mqe4/8Vxb/ghEhQ/wb4/dw1+9YmkwAAAAASUVORK5CYII=","aspectRatio":1.1627906976744187,"src":"/static/e417585de76300a95cd1db51557236ba/1c1a5/sparkstrucutredstreaming.png","srcSet":"/static/e417585de76300a95cd1db51557236ba/69585/sparkstrucutredstreaming.png 200w,\n/static/e417585de76300a95cd1db51557236ba/497c6/sparkstrucutredstreaming.png 400w,\n/static/e417585de76300a95cd1db51557236ba/1c1a5/sparkstrucutredstreaming.png 550w","sizes":"(max-width: 550px) 100vw, 550px"}}},"imageCredits":"unsplash"},"timeToRead":6}},{"node":{"id":"d1985f9d-ed7f-5bbe-ac6d-11ec68f914eb","html":"<h1>Creando una aplicacion con Spark Structured Streaming</h1>\n<h3>Codigo, configuraciones y consejos</h3>\n<p><a href=\"https://spark.apache.org/\">Apache Spark</a> es un framework de programación open-source para procesar datos masivos o big data, de forma distribuida, diseñado para ser rápido, y tolerante a fallas.\nTrabaja en memoria, con lo que se consigue mucha mayor velocidad de procesamiento.\nProporciona APIs para los lenguajes <code>Java</code>, <code>Scala</code>, <code>Python</code> y <code>R</code>.</p>\n<p>Utiliza la evaluación perezosa (<em>lazy</em>), lo que significa es que todas las transformaciones que vamos realizando sobre los RDD o Dataframes, no se resuelven, si no que se van almacenando en un grafo acíclico dirigido (<em>llamado DAG</em>), y cuando ejecutamos una acción, es decir, cuando la herramienta no tenga más opción que realizar todas las transformaciones, será cuando se ejecuten</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 684px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/544f7/apache-spark-circulo.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAAsTAAALEwEAmpwYAAABmUlEQVQoz41SXWvbMBTtL+/b3vcvSvfQp21txqAdhbSlW4MZlJJQiB3ipLFsSZZlfd6rYSv98Eg/zoM4SDq6516dvbALiC94eBV7OzUYgoFHivpD4ggDON88iOIeQ1DO/86uprNpnuf96x12iD1gq21HMFSNqIsFAnrEjBTWGkB8ozKuNuXZ5M55AAAMoSBV04OWZax2MR4nSZKm6f9iABCcMV4rB7Tq4L2PR85Zyli3RSnntZRyIEb0HgRgiN6stUKIENA4b9hGTb7VZG2d344UEQCexd4V4+vPBz+/nyazFakYraSUo5PRyejH0ZfD2/Nj2zDCa75Ip5/209lsvljERra2tdHScNz6dIyx5XJJK0rKShlT17VzrnPYyjjzYc/GWFKKh3WWZayHdS5+jGpbzjml1FqrjFFKvRD3zDBKk0l+8+fq8tL3LZVlKaXU2hBCurIhNE3DGOOcD3oehKxfhTJZvu79odJtFL+VMARAgPhDF3/vvv4ahxA2Yjlf3ZOiigVfTdggoVpp1cZ7AOCce7L6TrY/jn/famVIErhXjAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/e922d/apache-spark-circulo.webp 375w,\n/static/4e23ec14fd006dc3f61b43fa874ea9f0/ffa34/apache-spark-circulo.webp 684w\"\n              sizes=\"(max-width: 684px) 100vw, 684px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/ae393/apache-spark-circulo.png 375w,\n/static/4e23ec14fd006dc3f61b43fa874ea9f0/544f7/apache-spark-circulo.png 684w\"\n            sizes=\"(max-width: 684px) 100vw, 684px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/4e23ec14fd006dc3f61b43fa874ea9f0/544f7/apache-spark-circulo.png\"\n            alt=\"image\"\n            title=\"image\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">image</figcaption>\n  </figure></p>\n<p>Una de las más novedosas e interesantes funcionalidades de Spark es el <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\">Structured Streaming</a>, que permite procesar datos de forma escalable, tolerante a fallos y continua.</p>\n<p>La idea de Structure Streaming es procesar la data en tiempo real como si fuera una tabla que continuamente se actualiza con los nuevos valores, y permite realizar agregaciones sobre la misma.\nLos datos deben mantener una estructura definida, y el beneficio es que se pueden realizar operaciones basadas en el tiempo para decidir si los valores se deben considerar o descartar.</p>\n<p>Como ejemplo, para un proyecto debimos realizar unos cálculos en una ventana de las últimas 24 horas (sliding window), agregando los valores nuevos recibidos y descartando los viejos para obtener unas métricas que se actualizan cada 5 minutos.\nPara esto utilizamos la funcionalidad de Structured Streaming de Spark corriendo en un EMR cluster en AWS.</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 320px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/8980b/so-apache-spark-in-theory-enough-show-me-the-code.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 96.875%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAH/xAAXAQADAQAAAAAAAAAAAAAAAAABAwQC/9oADAMBAAIQAxAAAAGvuaxVM0QZokbjqAP/xAAYEAEBAQEBAAAAAAAAAAAAAAABAgAxEP/aAAgBAQABBQLNePIlZwGe0C//xAAaEQABBQEAAAAAAAAAAAAAAAACAAEQERIx/9oACAEDAQE/AXMb4tjP/8QAFhEBAQEAAAAAAAAAAAAAAAAAEQAQ/9oACAECAQE/ASN//8QAGRAAAwADAAAAAAAAAAAAAAAAARAhACIx/9oACAEBAAY/AnDc2C4H/8QAGxAAAwADAQEAAAAAAAAAAAAAAAERITGBUWH/2gAIAQEAAT8hTa0N9hbkdtuAg+DRZVdYI08y+GguGsw//9oADAMBAAIAAwAAABC4B3//xAAZEQADAAMAAAAAAAAAAAAAAAAAAREhMVH/2gAIAQMBAT8Qc6CltCeCH//EABgRAQADAQAAAAAAAAAAAAAAAAEAEBEx/9oACAECAQE/EBB2brZ//8QAHBABAQEBAAMBAQAAAAAAAAAAAREAITFhkUFx/9oACAEBAAE/EJtIW/3EV5pHvn7m1NvbrsEdL2esBSteqp+OAoldZyIBGboah89Y6VQr4u//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/5530d/so-apache-spark-in-theory-enough-show-me-the-code.webp 320w\"\n              sizes=\"(max-width: 320px) 100vw, 320px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/8980b/so-apache-spark-in-theory-enough-show-me-the-code.jpg 320w\"\n            sizes=\"(max-width: 320px) 100vw, 320px\"\n            type=\"image/jpeg\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/8f39fa53a1fc0b66872fbf6dadd8cd48/8980b/so-apache-spark-in-theory-enough-show-me-the-code.jpg\"\n            alt=\"image\"\n            title=\"image\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">image</figcaption>\n  </figure></p>\n<p>Algunos ejemplos iniciales se puede encontrar en la <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html\">documentación de spark</a></p>\n<p>Pero en la vida real suelen ser un poco más complejos, aquí les compartimos una versión simplificada de lo que hicimos:</p>\n<deckgo-highlight-code language=\"python\" terminal=\"ubuntu\"  >\n          <code slot=\"code\"># imports\nfrom datetime import datetime\nfrom pyspark.sql.types import StructType, StringType, StructField, \\\n   DoubleType, BooleanType, IntegerType\nfrom pyspark.sql import functions as F\n\n# definicion de variables\nhours_window = 24\nsliding_window = 5\ncheckpoint_dir = &#39;hdfs:///checkpoint_folder/&#39;\n\n# funcion para crear tipos facilmente\ndef _get_types(types_dict):\n   return StructType([(StructField(f_name, f_type, True)) for f_name, f_type in types_dict.items()])\n\n# definimos los tipos para la data que recibiremos\nLOGLINE_SCHEMA = _get_types({\n   &#39;timestamp&#39;: StringType(),\n   &#39;cost&#39;: DoubleType(),\n   &#39;clicks&#39;: DoubleType(),\n})\n\n# definimos del lector de streaming\nlogline_df = self.spark \\\n   .readStream \\\n   .schema(LOGLINE_SCHEMA) \\\n   .parquet(&#39;hdfs:///mydata/*&#39;)\n\n# convertimos en timestamp para poder usar la funcion window\nlogline_df = logline_df.withColumn(&#39;timestamp&#39;, F.to_timestamp(&#39;timestamp&#39;))\n\n\n# agregamos definicion de watermark\nlogline_df = logline_df.withWatermark(&#39;timestamp&#39;, &#39;1 minute&#39;)\n\n\n# calculamos las metricas que nos interesan \nmetrics_df = logline_df.groupBy(\n   F.window(\n      logline_df.timestamp, f&#39;{hours_window} hours&#39;, \n      f&#39;{sliding_window} minutes&#39;\n   ),\n   logline_df.campaign_eid\n) \\\n.agg(\n   F.sum(&#39;cost&#39;).alias(&#39;cost&#39;),\n   F.sum(&#39;clicks&#39;).alias(&#39;clicks&#39;)\n)\n\n\n# iniciamos el proceso de streaming\nquery = metrics_df.writeStream \\\n   .option(&quot;checkpointLocation&quot;, checkpoint_dir) \\\n   .foreachBatch(collect_metrics_fn) \\\n   .outputMode(&#39;append&#39;) \\\n   .trigger(processingTime=f&#39;{sliding_window} minutes&#39;) \\\n   .start()\n\n# funcion llamada para cada iteracion (batch)\n# aqui podemos manipular el df final que tendremos\ndef collect_metrics_fn(df, epoch_id):\n   # agregamos una columna\n   df = df.withColumn(&#39;timestamp&#39;, F.lit(datetime.now()))\n   # escribimos el dataframe en HDFS en formato parquet\n   df.write.mode(&#39;overwrite&#39;).parquet(&#39;hdfs:///output&#39;)</code>\n        </deckgo-highlight-code>\n<p>En el código podemos ver que en la función <code>.readStream</code>\ndefinimos que vamos a leer archivos del tipo parquet desde el path local en <code>/mydata/</code>\nEn este ejemplo estamos leyendo desde los archivos distribuidos Hadoop (HDFS).</p>\n<p>Más informacion acerca de HDFS:\n<a href=\"https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html\">https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html</a></p>\n<p>Con la definición de:</p>\n<deckgo-highlight-code language=\"python\" terminal=\"ubuntu\"  >\n          <code slot=\"code\">   F.window(\n      logline_df.timestamp, f&#39;{hours_window} hours&#39;, \n      f&#39;{sliding_window} minutes&#39;\n   )</code>\n        </deckgo-highlight-code>\n<p>creamos una ventana de tiempo sobre el campo timestamp de 24 horas (hours_window), que se va a desplazar cada 5 minutos.</p>\n<p>Para comenzar con el procesamiento debemos llamar a la función <code>writeStream</code>.\nLa definición de la carpeta <code>checkpoint</code> es importante, ya que si nuestro trabajo de streaming falla o es deployado nuevamente, intentará primero iniciar el trabajo desde el último checkpoint guardado, sin tener que procesar todos los datos nuevamente; siempre y cuando no haya cambios la estructura de la query que rompan la compatibilidad con el checkpoint. De ser así, es necesario remover la carpeta <em>manualmente</em> antes de iniciar nuevamente el proceso.</p>\n<p>El <code>outputMode</code>  define como queremos que las ventanas sean procesadas, con el modo <code>append</code> el resultado de cada ventana es escrito una sola vez, al finalizar el periodo definido en el <code>Watermark</code>, de esta forma cada ventana escrita es siempre final ya que no se espera que más datos puedan ingresar en esa ventana.</p>\n<p>A diferencia en el modo <code>update</code> si hay nuevos datos que entran en una ventana se re-escribe en el output la misma ventana.\nPueden ver más información en la <a href=\"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-modes\">documentación de spark</a> sobre los <code>output mode</code> de las ventanas disponibles.</p>\n<p>Y finalmente en la sección <code>foreachBatch</code> se puede agregar una función para ser llamada en cada iteración donde se puede manipular, agregar más información y escribir el dataframe al destino y en el formato necesario. El parametro <code>epoch_id</code> sirve para identificar unívocamente cada iteración y tener una garantia de escribir los datos una sola vez si es necesario.</p>\n<h3>Algunas configuraciones útiles para trabajos que corran por mucho tiempo</h3>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1100px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b9b0687874e23c0e576a988d6dda404a/28a3f/spark-defaults.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADKklEQVQozwXBWUybBQDA8Y+jrBz9SgujwIBBoVBbKqOsHKXS0FIoIA7G4SwKYjlKAA/CwE03jgTWadgYRQEBG6RAGGMhmct0kTnNEvXBPeiUZIlOiCZmyoPZXnzx7+8nnLMf5kJVApM18UzVp+JrK8TXnM10q5ErrmO8XabG+4KW0+V63ipN50d/C3/deA1/xzECPUU8vd3C4806bng0fDtsQhiriGOiSsWIQ4m3IZON5Y/YWJ5naXKU9aUFrs7PsDzez87NbS4On+Oyd4JPrwXYWl3k5tVP+OerXtjtYX+lmjsDBoTW4yJNOXJOZou8mBNNS34iroKjuHNU7Jwu4fGtPnbHrHz/ei7tuXHkxYjcGrSxHzjFVm8eT+644X4Hu1Nm1trUCE6tSFl6FM4sGc/r5FRrZdjSIpgoioG1Gtjt42DRyb3GRDbqkrDLQwi0GXl6vY5tdxr/fu7i0QclPHi/hEf+agSrOhKHJooanZyXjEpceUrqDQoGjUq+8+j5c9LK7yP57F2w8XDISGuqlPPlav5YrGKrI4sfvIXcfkPLwbVa/rvbgmBLl1GZJeLQyHguNYJclQS7OoJOrZyvOw2wdZK/3zPzZM7Or0PPMp6v4Kw5kZ/HLWx3ZbDmVvPNaBH7c3buj5kQilLCSRFDkUmCORIVxkyHmZ0BM4tVybxTGMdP/QY2alP5rFHDg24t7x6PplMfS322iq7iBAKvanh4ycbenJ0vBvQIUaHBxEpDUYUJvFmSzC/nzcw6klg/kcaQSUW3Ts7egBG8FtZPHMGpkmIQDyERghDDw2kuSKCrUEGvRcm9ETNCtCQYvSKMZGkQq24TXzalcsYgY7P5GRbK40kSBDzZEfQaDuGMEWhPj8QcH0G0NAiHTqShIAGLNg5ThoLK3FiEtMgQMuWhpEiD2Owr5mC4gN9mXmH/Yw8vm3WUWoqpKTFSY7fSVWFltKmc/lMVeOpLGe1poLXSSHWOijJDPFZ9HEKGXEKGGEKmGMIZh5q77kwWBju5PD1Lu9uNzzeN78olVuanuO7zsvLhNMsLM6z6Z/EvLXK220Wj6TANhUepNSbyP5o+yRGWAWZAAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/b9b0687874e23c0e576a988d6dda404a/e922d/spark-defaults.webp 375w,\n/static/b9b0687874e23c0e576a988d6dda404a/3ea8a/spark-defaults.webp 750w,\n/static/b9b0687874e23c0e576a988d6dda404a/cb2d6/spark-defaults.webp 1100w\"\n              sizes=\"(max-width: 1100px) 100vw, 1100px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/b9b0687874e23c0e576a988d6dda404a/ae393/spark-defaults.png 375w,\n/static/b9b0687874e23c0e576a988d6dda404a/e9985/spark-defaults.png 750w,\n/static/b9b0687874e23c0e576a988d6dda404a/28a3f/spark-defaults.png 1100w\"\n            sizes=\"(max-width: 1100px) 100vw, 1100px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/b9b0687874e23c0e576a988d6dda404a/28a3f/spark-defaults.png\"\n            alt=\"image\"\n            title=\"image\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">image</figcaption>\n  </figure></p>\n<p><code>spark.sql.streaming.minBatchesToRetain</code></p>\n<p>Esta configuración indica la cantidad mínima de checkpoints que se van a guardar para hacer un recovery en caso de que haya un error.\nEl default es 100, pero puede hacer crecer mucho la carpeta del checkpoint en caso de que sean muchos datos, por esto nosotros utilizamos un valor de 5.</p>\n<p><code>spark.cleaner.referenceTracking.cleanCheckpoints</code></p>\n<p>También esta configuración que por default está en false, cambiando a true elimina los checkpoints que se encuentran sin referencia.</p>\n<p><code>spark.default.parallelism</code></p>\n<p>Esto indica cuanto paralelismo puede tener un trabajo, lo cual depende del hardware provisionado. Mucho paralelismo hará que las tareas sean muy chicas y genere mucho overhead y poco hará que se sub-utilice los recursos de los executors.</p>\n<p>Un cálculo simple para saber qué valor utilizar sería el siguiente:\n<code>spark.default.parallelism = spark.executor.instances * spark.executors.cores * 2 (or 3)</code></p>\n<p><em>Más configuraciones que podrían ser útiles para trabajos de Structured Streaming pueden ser encontradas aqui</em>\n<a href=\"https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-properties.html\">https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-properties.html</a></p>\n<h3>Deployar una aplicación Spark en EMR con yarn</h3>\n<p><code>aws emr add-steps --cluster-id ClusterID --steps Type=spark,Name=MyApp,Args=[--deploy-mode,cluster,--master,yarn,--conf,spark.yarn.submit.waitAppCompletion=False,--conf,spark.yarn.appMasterEnv.profile=$(profile),--py-files,s3://my-bucket/app-dependencies.zip,s3://my-bucket/my_app.py],ActionOnFailure=CONTINUE</code></p>\n<p>Con el comando aws emr add-steps podemos agregar un step que va a crear una aplicación, y al elegir <code>waitAppCompletion=False</code> el step terminara al deployar, al ser un job de streaming idealmente no tendra una finalización.</p>\n<p>Y con este parámetro:\n<code>spark.yarn.appMasterEnv.profile</code></p>\n<p>Podemos pasar variables de entorno a la aplicación para su ejecución, como por ejemplo el profile (<em>staging / producción</em>), un ejemplo de como usar esa variable del código en python:</p>\n<p><code>PROFILE = os.getenv('profile', 'staging')</code></p>\n<p><strong>Spark structured streaming</strong> es una gran herramienta pero requiere esfuerzo y conocimiento para poder obtener resultados satisfactorios. Esperamos que les sirva a los nuevos aventurados en el tema.</p>","frontmatter":{"lang":"es","type":"post","title":"Spark Strucutred Streaming","author":"Agustin Recouso","slug":"/spark-structured-streaming","date":"2022-01-24","tags":["python","spark","big-data"],"image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAIAAABSJhvpAAAACXBIWXMAAAsTAAALEwEAmpwYAAACe0lEQVQ4y5VT30/TUBjtH2diIo8YSiIPQmQQS3RB0ABLEPoATH4NHWNbqaLDkcgDEXBCRmFhhsGWjHUgI9nKWEkV19lu7ehc23sN6VzMshg5ubn57s05+b6bew4CbwgAANC16wUAciPRj9BmWRKNI4QQqcOpAYRA1yCEv35e7nXeOlt6VRb47MGWcslWxLqu/2HWbwshZNc9zOLUmXfmxPY0hN0uXqRqOxcK+VwuJ4qiLMv5vCgKQkEp8XTooKcx4xkvC1kIYfLNWC4arIwNACBJsru7m2VZmqYTiZNwOBwMBjmOo2OH++HI1bfM97ej2+7xXF4CmpqwDwhHBxUxRVEoim5sbLBsxufzzc05eJ5X1bLX+54kyWKxmEyff6a2n/U+cRDEqtsW72s6sVsqYkmSULTJ7/cvL38YGhqamprE8WGHY3ZiYhzH8ZHRkd7eHrfL2Xi30WQylRTliktfXV5ci1VV5TguFAo1NNxpb3+QyWQYhsGwh62t92VZZhimpeWexTKQTCabm5vMZvN5Om28tCLGMKytrdVmm0ZRtKPDZDY/Pj1NeDzvurowq3UMx4fn54loNGq1jlHUVn9/nyiKpVKpMrYgCCzLplLJwcFBnud3AgFqJ5BimHWfb+2TL0bHw5FIYHdXkiQIIc/zsiyDqkmMSlGUbPb6J/bDkVkn4SLIF5PTxOuFWafb7nQteBarzCqQqquqDtN1XdM0Y19ZXdv0U0fHXw9jdIyOf9kLxY+OJUk2mEiNN2s8s/JxzeNdemmfszwfnrE7HC6is+tRjI4bpkTqRqBaa5qmqioAQNM0457n+UJBqtP5H4mqe4/8Vxb/ghEhQ/wb4/dw1+9YmkwAAAAASUVORK5CYII=","aspectRatio":1.1627906976744187,"src":"/static/e417585de76300a95cd1db51557236ba/1c1a5/sparkstrucutredstreaming.png","srcSet":"/static/e417585de76300a95cd1db51557236ba/69585/sparkstrucutredstreaming.png 200w,\n/static/e417585de76300a95cd1db51557236ba/497c6/sparkstrucutredstreaming.png 400w,\n/static/e417585de76300a95cd1db51557236ba/1c1a5/sparkstrucutredstreaming.png 550w","sizes":"(max-width: 550px) 100vw, 550px"}}},"imageCredits":"unsplash"},"timeToRead":6}}]}},"pageContext":{"slug":"/spark-structured-streaming","language":"es","intl":{"language":"es","languages":["es","en"],"messages":{"Home":"Home","Servicios":"Servicios","Cultura":"Cultura","Labs":"Labs","Blog":"Blog","Articles":"Articles","footer.designby":"Un trabajo intercooperativo de","footer.coopName":"el maizal y nayra","footer.coopName1":"el maizal","footer.coopName2":"nayra","footer.coopName1Path":"https://elmaizal.coop.ar","footer.coopName2Path":"https://nayra.coop","footer.preposition":"y","footer.disclaimer":"Salvo que se indique lo contrario, el contenido de este sitio tiene una licencia de ","footer.licenseName":"Creative Commons Attribution","footer.licenseIconAlt":"Creative Commons Attribution logo","header.logoAlt":"logo Fiqus","header.iconTogglerAlt":"icono para abrir menú","header.iconTogglerCloseAlt":"icono para cerrar menú","homepage.title":"Homepage","homepage.imageAlt":" ","homepage.imageAltMobile":" ","homepage.leadLine1":"Somos una ","homepage.leadUnderlined":"cooperativa ","homepage.leadLine2":"de software. Somos ","homepage.leadBold":"construcción colectiva","homepage.leadLine3":", cultura y mentes en constante movimiento.","homepageCulture.title":"Cultura","homepageCulture.birdImage":"bird.svg","homepageCulture.birdImageAlt":"ilustración de un pájaro","homepageCulture.image":"homepageCulture.svg","homepageCulture.imageAlt":"ilustración que representa la sección cultura","homepageCulture.descriptionLine1":"Contamos con un superpoder: ¡Ser dueñ@s de la empresa en la que trabajamos! Fiqus no es un trabajo más, es un ","homepageCulture.underlinedText":"proyecto de vida","homepageCulture.descriptionLine2":" ,en el que construimos un equipo consolidado de profesionales que se encuentra en continua capacitación para poder brindar soluciones técnicas de alta calidad. ","homepageCulture.btnText":"ver más","homepageLabs.title":"Labs","homepageLabs.subtitle":"¡Nos capacitamos permanentemente!","homepageLabs.image":"homepageLabs.svg","homepageLabs.imageAlt":"ilustración que representa la sección cultura","homepageLabs.imageAltMobile":"ilustración que representa la sección cultura","homepageLabs.descriptionLine1":"Uno de los objetivos de Fiqus es capacitarnos constantemente para especializarnos en tecnologías de vanguardia, por eso todas las semanas tenemos","homepageLabs.descriptionBold1":" FiqusLabs","homepageLabs.descriptionLine2":" un espacio de aprendizaje práctico donde investigamos tecnologías de vanguardia como","homepageLabs.descriptionBold2":" Elixir","homepageLabs.descriptionComma":",","homepageLabs.descriptionBold3":" Erlang","homepageLabs.descriptionLine4":" y","homepageLabs.descriptionBold4":" MachineLearning","homepageLabs.descriptionDot":".","homepageLabs.btnText":"ver más","button.verMas":"ver más","button.send":"enviar","button.read":"leer","verMasArticulos":"ver todos los artículos","y":" y ","contactForm.title":"Contactanos","contactForm.nameField":"Nombre","contactForm.emailField":"E-mail","contactForm.requiredFieldError":"Por favor, complete el campo requerido.","contactForm.textAreaField":"Mensaje","contactForm.messageSent":"Tu mensaje ha sido enviado.","contactForm.thankYou":"Gracias por comunicarte con nosotr@s","contactForm.email":"info@fiqus.coop","contactForm.sedes":"Sedes","contactForm.office1":"14 de Julio 1268 Ciudad de Buenos Aires, Argentina","contactForm.office2":"Las Frutillas 109, Casa 2 Villa La Angostura, Neuquén, Argentina","services.title":"Servicios","services.tagsTitle":"Tecnologías","services.btnText":"ir a servicios","service_datos.service":"Ciencia de Datos","service_datos.description":"Este área se dedica a la limpieza, extracción y análisis de datos con el fin de poder servir de alimento para procesos de Inteligencia Artificial o Aprendizaje Automático. Es de esencial importancia procesar los datos para lograr que sean de fácil entendimiento, así como su uso para llegar a los objetivos planteados.","service_datos.tags.0":"Python","service_datos.tags.1":"Pandas","service_datos.tags.2":"Numpy","service_datos.tags.3":"Seaborn","service_datos.image":"datos","service_datos.link":" ","service_inteligenciaArtificial.service":"Inteligencia Artificial","service_inteligenciaArtificial.description":"El Aprendizaje Automático es un subcampo de la Inteligencia Artificial en el que se tiene como objetivo que las \"computadoras aprendan\". A partir de datos recolectados y procesados, diseñamos, construimos y entrenamos modelos que nos permitan predecir eventos futuros, clasificar imágenes, reconocer entidades en textos y muchas otras cosas más.","service_inteligenciaArtificial.tags.0":"Python","service_inteligenciaArtificial.tags.1":"Pandas","service_inteligenciaArtificial.tags.2":"Numpy","service_inteligenciaArtificial.tags.3":"Seaborn","service_inteligenciaArtificial.image":"inteligenciaArtificial","service_inteligenciaArtificial.link":" ","service_altaConcurrencia.service":"Alta Concurrencia","service_altaConcurrencia.description":"Utilizamos lenguajes de programación funcional en tiempo real y muy adoptados en el mercado, que soportan niveles de altísima concurrencia y distribución, teniendo como resultado sistemas que responden a gran velocidad ante altas demandas.","service_altaConcurrencia.tags.0":"Earlang","service_altaConcurrencia.tags.1":"Elixir","service_altaConcurrencia.tags.2":"Phoenix Framework","service_altaConcurrencia.tags.3":"LiveView","service_altaConcurrencia.image":"altaConcurrencia","service_altaConcurrencia.link":" ","service_blockchain.service":"Blockchain | Fintech","service_blockchain.description":"Estamos desarrollando fintech, que son las nuevas aplicaciones, procesos, productos o modelos de negocios en la industria de los servicios financieros compuestos de uno o más servicios financieros complementarios y puestos a disposición del público vía Internet.","service_blockchain.tags.0":"Python","service_blockchain.tags.1":"Ethereum","service_blockchain.image":"blockchain","service_blockchain.link":" ","service_fullstack.service":"Fullstack","service_fullstack.description":"Desarrollamos aplicaciones web/mobile/desktop con diferentes tecnologías que permitan resolver problemáticas de organizaciones, cooperativas y empresas y poder realizar sus procesos de manera más eficiente.","service_fullstack.tags.0":"Django","service_fullstack.tags.1":"Phoenix","service_fullstack.tags.2":"Phoenix LiveView","service_fullstack.tags.3":"ReactJS","service_fullstack.tags.4":"VueJS","service_fullstack.tags.5":"React Native","service_fullstack.image":"fullstack","service_fullstack.link":" ","service_subsection.title":"Capacitación","service_subsection.description":"Realizamos capacitaciones técnicas y/o de cooperativismo para organizaciones, cooperativas y empresas donde buscamos transmitir de forma amena y sistematizada los conocimientos adquiridos en el ámbito tecnológico y cooperativo.","service_subsection.image":"capacitacion","service_subsection.featuredServiceImageAlt":"Capacitación, ilustración animada","service_subsection.link":"servicios/#capacitacion","culture.title":"Cultura","culture.subtitle":"Contamos con un superpoder: ¡Ser dueñ@s de la empresa en la que trabajamos!","culture.description":"Fiqus no es un trabajo más, es un proyecto de vida, en el que construimos un equipo consolidado de profesionales que se encuentra en continua capacitación para poder brindar soluciones técnicas de alta calidad. ","culture_historia.title":"Historia","culture_historia.imageMobile":"equipoMobile","culture_historia.imageAltMobile":"equipo Fiqus","culture_historia.imageDesktop":"equipoDesktop","culture_historia.imageAlt":"equipo Fiqus","culture_historia.content_line1":"Fiqus es como una gran familia, que comenzó cuando varios estudiantes de ingeniería en sistemas de la Universidad Tecnológica Nacional se cansaron de los trabajos tradicionales y comenzaron a pensar en una construcción propia, con lógicas de producción diferentes a las de las empresas en las que habían trabajado previamente","culture_historia.content_line2":"Luego de varios meses de gestación, la idea de construir algo autogestivo, horizontal, democrático y de propiedad colectiva se hizo cada vez más fuerte. Así es como nació la idea de construir una empresa social, así es como nació Fiqus.","culture_historia.content_line3":"Con el transcurso de los años fuimos construyendo una estructura organizacional que se adapta a las personas y no al revés. Así es como, sobre el andar y basándonos en la experiencia adquirida, construimos una serie de acuerdos que hoy en día forman parte de nuestro reglamento interno. Nuestro reglamento no es algo estático, es algo vivo que evoluciona acorde evolucionan las personas que forman parte de nuestra organización. Ahí es donde reflejamos nuestras propuestas concretas para lograr que las personas que participan dentro del colectivo se ubiquen en el centro de los procesos productivos.","culture_historia.content_line4":"Nos gusta pensar que Fiqus es una propuesta que invita a quienes no conocen al cooperativismo tecnológico a ver que un cambio de paradigma es posible.","culture_historia.subtitle":"¡Nos organizamos horizontal y democráticamente!","culture_historia.content_line5":"Las decisiones de la cooperativa se plasman en la Asamblea General Ordinaria una vez al año. Además como forma de organización colectiva realizamos dos veces al año un encuentro donde pensamos, a partir de los deseos personales, nuestros objetivos como cooperativa y semanalmente nos encontramos (de manera virtual) a planificar las tareas diarias. ","culture_federales.title1":"¡Somos federales!","culture_federales.image":"mapa_argentina","culture_federales.imageAlt":" ","culture_federales.content1":"Nuestra distribución actual es el resultado de haber creado una estructura lo suficientemente maleable como para que logre adaptarse a las necesidades de las personas. De esta manera, a medida que fuimos creciendo como personas y transitando los diferentes escenarios que la vida nos fue planteando, priorizamos acompañar desde el colectivo brindando el apoyo necesario para que todxs puedan decidir por ejemplo en dónde y cómo vivir.","culture_federales.tenemosSedes":"En la actualidad tenemos sedes en ","culture_federales.y":"y","culture_federales.personasAsociadas":"Pero además, contamos con personas asociadas trabajando desde ","culture_federales.title2":"Territorial","culture_federales.content2":"Como cooperativa de trabajo, nos entendemos como actores sociales territoriales. Apoyándonos en el séptimo principio cooperativo de “Compromiso con la Comunidad”, asumimos la responsabilidad de extender la construcción colectiva que realizamos día a día dentro de la cooperativa en el territorio perteneciente a una de nuestras sedes. Es por esto que trabajamos activamente en la Mesa de Asociativismo de Villa La Angostura, Neuquén. Allí nos reunimos en forma periódica junto con otros actores y actrices de la economía social así como con personas individuales comprometidas con la comunidad local para desarrollar proyectos que potencien iniciativas locales, siempre con una mirada colaborativa y horizontal.","culture_facttic.title":"¡Estamos federados en FACTTIC!","culture_facttic.subtitle":"La federación es una organización nacional que está conformada por cooperativas tecnológicas de toda Argentina.","culture_facttic.content_line1_part1":"Todo comenzó cuando las primeras cooperativas del sector comenzamos a ponernos en contacto entre nosotras porque entendimos que en la unión está la fuerza para poder construir un modelo que escale con el objetivo de convertirse poco a poco en una alternativa real al modelo de producción tradicional. Producto de esas primeras interacciones nació la idea de firmar una carta de compromiso para fundar la ","culture_facttic.content_line1_facttic":"Federación Argentina de Cooperativas de Tecnología Innovación y Conocimiento (FACTTIC)","culture_facttic.content_line1_part2":", un espacio de construcción colectiva que fomenta la solidaridad y la colaboración como motores que impulsan la creación de tecnología con valores cooperativos.","culture_facttic.content_line2":"El contacto continuo con otras cooperativas de nuestro sector y el trabajar en conjunto para desarrollar estrategias comunes y compartir conocimiento genera un círculo virtuoso en constante evolución que nos impulsa a crecer y seguir potenciando nuestro trabajo.","culture_facttic.content_line3":"La federación nos permite estar en contacto con otras realidades, nos permite romper con la endogamia de nuestra organización y nos invita a pensarnos como algo más grande, que abarca una escala mayor. Es un espacio de creación colectiva donde la imaginación aplicada a la construcción colaborativa no encuentra límites.","culture_internacional.title":"Internacional","culture_internacional.content_line1":"Varios años después de haber participado de la creación de la federación, comenzamos a contactarnos con cooperativas tecnológicas de otras partes del mundo con el objetivo de compartir el modelo de colaboración e intercooperación construido con cooperativas locales a una escala más global.","culture_internacional.content_line2":"Luego de varias interacciones, realizamos el primer viaje intercooperativo internacional de nuestra red. Viajamos a Reino Unido para conocer a cooperativas tecnológicas de una red local. Compartimos experiencias y comenzamos a construir las bases de lo que hoy constituye la Red Global de Cooperativas de Tecnología.","culture_internacional.content_line3":"La red nuclea a más de 45 cooperativas tecnológicas de todo el mundo, con presencia en 3 continentes. Compartimos reuniones semanales en las que aprendemos de nuestras culturas, debatimos acerca de nuestros objetivos comunes y delineamos una hoja de ruta para hacer crecer a la comunidad que la compone. De a poco, comenzamos a intercooperar con el objetivo de fortalecer nuestras construcciones locales con una mirada de escala global. De esta manera, organizadas, las cooperativas de tecnología podremos ayudarnos mediante la cooperación a vender y desarrollar proyectos en conjunto.","labs.title":"Labs","labs.subtitle":"FiqusLabs es un espacio donde investigamos sobre nuevas tecnologías y nos capacitamos.","labs.content":"De yapa, muchas veces el aprendizaje de una nueva tecnología viene acompañado con poder plasmar un proyecto que beneficie a la comunidad o al ambiente cooperativo.","casos_de_exito.title":"Casos de Éxito","casos_de_exito.tagsTitle":"Tecnologías Investigadas","casos_de_exito.imageAltLine1":"imagen del proyecto ","casos_de_exito.btnTextVerMas":"ver más","casos_de_exito.btnTextGithub":"ir a Github","blog.title":"Blog","blogPost.tagsTitle":"Etiquetas relacionadas","blogPost.relatesPost":"Artículos relacionados","blogPost.verTodosBtn":"Ver todos los artículos","page404.title":"Error 404","page404.descriptionLine1":"No pudimos encontrar lo que estabas buscando. Si necesitás ayuda contactate con nosotr@s.","page404.descriptionLine2":"Te invitamos a seguir navegando nuestro sitio tocando el siguiente botón","page404.btnText":"volver al home","page404.btnHref":"/","page404.imageAlt":"ilustración árbol fiqus","page404.imageAltMobile":"ilustración árbol fiqus"},"routed":false,"originalPath":"/post/spark-structured-streaming","redirect":true,"redirectDefaultLanguageToRoot":false,"defaultLanguage":"es","fallbackLanguage":"es","ignoredPaths":[]}}},
    "staticQueryHashes": ["632761789"]}